{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.io import imread\n",
    "from matplotlib.collections import PatchCollection\n",
    "from matplotlib.patches import Rectangle\n",
    "import numpy as np\n",
    "map_base_dir = '../input/'\n",
    "map_img_dir = '../input/train/images/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "json_path = os.path.join(map_base_dir, 'annotation.json')\n",
    "with open(json_path, 'r') as f:\n",
    "    annot_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c2274d93114bdb919696985bc0a1aa7ca4872a9e",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_df = pd.DataFrame(annot_data['images'])\n",
    "image_df.sample(3)\n",
    "fig, m_axs = plt.subplots(2, 2, figsize = (10, 10))\n",
    "for c_ax, (_, c_row) in zip(m_axs.flatten(), image_df.sample(4).iterrows()):\n",
    "    img_data = imread(os.path.join(map_img_dir, c_row['file_name']))\n",
    "    c_ax.imshow(img_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "dfddddbbe83a4ff06aa3c443b2b8f68057bf834a",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "annot_df = pd.DataFrame(annot_data['annotations'])\n",
    "annot_df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c32e0c755deef724cd5e6a062d4e0284b1f57c25",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full_df = pd.merge(annot_df, image_df, how='left', left_on = 'image_id', right_on='id').dropna()\n",
    "print(image_df.shape[0], '+', annot_df.shape[0], '->', full_df.shape[0])\n",
    "full_df.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "bed275ea741ff16c7a306afa735fe27637718c4f",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_boxes(in_rows):\n",
    "    #TODO: this seems to get a few of the boxes wrong so we stick to segmentation polygons instead\n",
    "    box_list = []\n",
    "    for _, in_row in in_rows.iterrows():\n",
    "        # bbox from the coco standard\n",
    "        (start_y, start_x, wid_y, wid_x) = in_row['bbox']\n",
    "        \n",
    "        box_list += [Rectangle((start_x, start_y), \n",
    "                         wid_y , wid_x\n",
    "                         )]\n",
    "    return box_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "bcecbf664e882bdb92eaff5fe4aab92d8121f844",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig, m_axs = plt.subplots(2, 2, figsize = (10, 10))\n",
    "for c_ax, (c_id, c_df) in zip(m_axs.flatten(), full_df.groupby('image_id')):\n",
    "    img_data = imread(os.path.join(map_img_dir, c_df['file_name'].values[0]))\n",
    "    c_ax.imshow(img_data)\n",
    "    #c_ax.add_collection(PatchCollection(create_boxes(c_df), alpha = 0.25, facecolor = 'red'))\n",
    "    for _, c_row in c_df.iterrows():\n",
    "        xy_vec = np.array(c_row['segmentation']).reshape((-1, 2))\n",
    "        c_ax.plot(xy_vec[:, 0], xy_vec[:, 1], label = c_df['id_x'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f7cd3806579db2ce31f6f7dd3feebbbe5f9f9047"
   },
   "source": [
    "# Convert Polygons to Segmentations\n",
    "We can use the `Path` function of matplotlib on a `np.meshgrid` of $x,y$ values in order to convert the polygon into a binary image to use as the segmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5311b010517d3a780cc6d13637db3b6f1cc6a624",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from matplotlib.path import Path\n",
    "from skimage.color import label2rgb\n",
    "def rows_to_segmentation(in_img, in_df):\n",
    "    xx, yy = np.meshgrid(range(in_img.shape[0]), \n",
    "                range(in_img.shape[1]),\n",
    "               indexing='ij')\n",
    "    out_img = np.zeros(in_img.shape[:2])\n",
    "    for _, c_row in in_df.iterrows():\n",
    "        xy_vec = np.array(c_row['segmentation']).reshape((-1, 2))\n",
    "        c_ax.plot(xy_vec[:, 0], xy_vec[:, 1], label = c_df['id_x'])\n",
    "        xy_path = Path(xy_vec)\n",
    "        out_img += xy_path.contains_points(np.stack([yy.ravel(), \n",
    "                                                     xx.ravel()], -1)).reshape(out_img.shape)\n",
    "    return out_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0a119b76462fac4299851de1d21073c30265c56e",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig, m_axs = plt.subplots(3, 3, figsize = (15, 20))\n",
    "for (c_ax, d_ax, f_ax), (c_id, c_df) in zip(m_axs,\n",
    "                                      full_df.groupby('image_id')):\n",
    "    img_data = imread(os.path.join(map_img_dir, c_df['file_name'].values[0]))\n",
    "    c_ax.imshow(img_data)\n",
    "    out_img = rows_to_segmentation(img_data, c_df)\n",
    "    rgba_img = np.concatenate([img_data, \n",
    "                               np.clip(np.expand_dims(127*out_img+127, -1), 0, 255).astype(np.uint8)\n",
    "                              ], -1)\n",
    "    d_ax.imshow(rgba_img)\n",
    "    \n",
    "    f_ax.imshow(label2rgb(image=img_data, label=out_img, bg_label = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c89e85ccb84db86f1b8c415485f6a3254d01add0",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_ids, valid_ids = train_test_split(image_df['id'], test_size = 0.25)\n",
    "train_df = full_df[full_df['image_id'].isin(train_ids)]\n",
    "valid_df = full_df[full_df['image_id'].isin(valid_ids)]\n",
    "print(train_df.shape[0], 'training boxes')\n",
    "print(valid_df.shape[0], 'validation boxes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3d1f8997ad602e9b2a69bb81ad1aa2e5d4841aa3",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def batch_img_gen(in_df, batch_size):\n",
    "    all_groups = list(in_df.groupby('image_id'))\n",
    "    out_img, out_seg = [], []\n",
    "    while True:\n",
    "        for (_, c_df) in np.random.permutation(all_groups):\n",
    "            img_data = imread(os.path.join(map_img_dir, c_df['file_name'].values[0]))\n",
    "            out_img += [img_data]\n",
    "            out_seg += [np.expand_dims(rows_to_segmentation(img_data, c_df), -1)]\n",
    "            if len(out_img)>=batch_size:\n",
    "                yield (np.stack(out_img, 0)/255.0).astype(np.float32), np.stack(out_seg, 0).astype(np.float32)\n",
    "                out_img, out_seg = [], []\n",
    "valid_gen = batch_img_gen(valid_df, 8)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "13bc7a7d02e3aea6a7e7cea833b37d5431fe6d25",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from skimage.util.montage import montage2d\n",
    "t_x, t_y = next(valid_gen)\n",
    "print('x', t_x.shape, t_x.dtype, t_x.min(), t_x.max())\n",
    "print('y', t_y.shape, t_y.dtype, t_y.min(), t_y.max())\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (20, 10))\n",
    "montage_rgb = lambda x: np.stack([montage2d(x[:, :, :, i]) for i in range(x.shape[3])], -1)\n",
    "ax1.imshow(montage_rgb(t_x))\n",
    "ax2.imshow(montage2d(t_y[:, :, :, 0]), cmap = 'bone_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2a568e0e6359df9932d5c262044c59c881fabf67",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BLOCK_COUNT = 1\n",
    "EDGE_CROP = 16\n",
    "BASE_DEPTH = 16\n",
    "SPATIAL_DROPOUT = 0.25\n",
    "GAUSSIAN_NOISE = 0.1\n",
    "BATCH_SIZE = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "cf3878a9425fe75b2f945a07940e76c91b18c106",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import models, layers\n",
    "def conv_bn(x, filt, dl_rate=(1,1), preblock = False):\n",
    "    y = layers.Convolution2D(filt, (3, 3), \n",
    "                             activation='linear', \n",
    "                             padding='same', \n",
    "                             dilation_rate=dl_rate,\n",
    "                            use_bias=False)(x)\n",
    "    if preblock: return y\n",
    "    y = layers.BatchNormalization()(y)\n",
    "    return layers.Activation('elu')(y)\n",
    "\n",
    "in_layer = layers.Input(t_x.shape[1:], name = 'RGB_Input')\n",
    "pp_in_layer = layers.GaussianNoise(GAUSSIAN_NOISE)(in_layer)\n",
    "pp_in_layer = layers.BatchNormalization()(pp_in_layer)\n",
    "\n",
    "c = conv_bn(pp_in_layer, BASE_DEPTH//2)\n",
    "c = conv_bn(c, BASE_DEPTH//2)\n",
    "c = conv_bn(c, BASE_DEPTH)\n",
    "\n",
    "skip_layers = [pp_in_layer]\n",
    "for j in range(BLOCK_COUNT):\n",
    "    depth_steps = int(np.log2(t_x.shape[1])-2)\n",
    "    d = layers.concatenate(skip_layers+[conv_bn(c, BASE_DEPTH*2**j, (2**i, 2**i), preblock=True) \n",
    "                                        for i in range(depth_steps)])\n",
    "    d = layers.SpatialDropout2D(SPATIAL_DROPOUT)(d)\n",
    "    d = layers.BatchNormalization()(d)\n",
    "    d = layers.Activation('elu')(d)\n",
    "    # bottleneck\n",
    "    d = conv_bn(d, BASE_DEPTH*2**(j+1))\n",
    "    skip_layers += [c]\n",
    "    c = d\n",
    "d = layers.Convolution2D(1, (1, 1), activation='sigmoid', padding='same')(d)\n",
    "d = layers.Cropping2D((EDGE_CROP, EDGE_CROP))(d)\n",
    "d = layers.ZeroPadding2D((EDGE_CROP, EDGE_CROP))(d)\n",
    "seg_model = models.Model(inputs = [in_layer],\n",
    "                    outputs = [d])\n",
    "seg_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5d05b462cf4616b2665dc9d47b5a0d150f4dad1f",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import binary_crossentropy\n",
    "def dice_coef(y_true, y_pred, smooth=1):\n",
    "    intersection = K.sum(y_true * y_pred, axis=[1,2,3])\n",
    "    union = K.sum(y_true, axis=[1,2,3]) + K.sum(y_pred, axis=[1,2,3])\n",
    "    return K.mean( (2. * intersection + smooth) / (union + smooth), axis=0)\n",
    "def dice_p_bce(in_gt, in_pred):\n",
    "    return 0.05*binary_crossentropy(in_gt, in_pred) - dice_coef(in_gt, in_pred)\n",
    "def true_positive_rate(y_true, y_pred):\n",
    "    return K.sum(K.flatten(y_true)*K.flatten(K.round(y_pred)))/K.sum(y_true)\n",
    "seg_model.compile(optimizer=Adam(1e-4, decay=1e-6), loss=dice_p_bce, metrics=[dice_coef, 'binary_accuracy', true_positive_rate])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4d2690c144301388ad9e9313d51cea1f617d3a7b",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau\n",
    "weight_path=\"{}_weights.best.hdf5\".format('seg_model')\n",
    "\n",
    "checkpoint = ModelCheckpoint(weight_path, monitor='val_dice_coef', verbose=1, \n",
    "                             save_best_only=True, mode='max', save_weights_only = True)\n",
    "\n",
    "reduceLROnPlat = ReduceLROnPlateau(monitor='val_dice_coef', factor=0.5, \n",
    "                                   patience=3, \n",
    "                                   verbose=1, mode='max', epsilon=0.0001, cooldown=2, min_lr=1e-6)\n",
    "early = EarlyStopping(monitor=\"val_dice_coef\", \n",
    "                      mode=\"max\", \n",
    "                      patience=15) # probably needs to be more patient, but kaggle time is limited\n",
    "callbacks_list = [checkpoint, early, reduceLROnPlat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9ab9492175040e6e842c5083e378826f4094df0f",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "valid_gen = batch_img_gen(valid_df, BATCH_SIZE)\n",
    "loss_history = [seg_model.fit_generator(batch_img_gen(train_df, BATCH_SIZE), \n",
    "                             steps_per_epoch=min(train_ids.shape[0]//BATCH_SIZE, 100),\n",
    "                             epochs=2, \n",
    "                             validation_data = valid_gen,\n",
    "                             validation_steps = min(train_ids.shape[0]//BATCH_SIZE, 50),\n",
    "                             callbacks=callbacks_list,\n",
    "                            workers=2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "87c89ad9a5bbd53aea5ae1c14d96fdeb9bb8ac9f",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seg_model.load_weights(weight_path)\n",
    "seg_model.save('full_best_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "97e72a7cecef74dc5da4cb356901a8a04744ffe8",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t_x, t_y = next(valid_gen)\n",
    "if t_x.shape[0]>16:\n",
    "    t_x = t_x[:16]\n",
    "    t_y = t_y[:16]\n",
    "    \n",
    "print('x', t_x.shape, t_x.dtype, t_x.min(), t_x.max())\n",
    "print('y', t_y.shape, t_y.dtype, t_y.min(), t_y.max())\n",
    "pred_y = seg_model.predict(t_x)\n",
    "\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize = (24, 8))\n",
    "montage_rgb = lambda x: np.stack([montage2d(x[:, :, :, i]) for i in range(x.shape[3])], -1)\n",
    "ax1.imshow(montage_rgb(t_x))\n",
    "ax2.imshow(montage2d(t_y[:, :, :, 0]), cmap = 'bone_r')\n",
    "ax2.set_title('Ground Truth')\n",
    "ax3.imshow(montage2d(pred_y[:, :, :, 0]), cmap = 'bone_r')\n",
    "ax3.set_title('Prediction')\n",
    "fig.savefig('pred_fig.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6cd5347d29023e88383d1638df7ecb04f59e3f6f",
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
